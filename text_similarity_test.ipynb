{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 此腳本為測試 stence-tranformers 文章向量的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path('/Users/zoe/Desktop/Kevin_project/judicial_analysis')\n",
    "input_path = root_path / '108/upload10812'\n",
    "supreme_court_path = root_path / '199601/最高法院民事'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step1. load civial code judical include 車禍 (supreme + 14,904 normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_judicial = []\n",
    "\n",
    "for file in supreme_court_path.glob('*'):\n",
    "    with open(file, 'r') as f:\n",
    "        judicial_json = json.loads(f.read())\n",
    "    \n",
    "    if '車禍' in judicial_json['JFULL']:\n",
    "        accident_judicial.append(judicial_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2. check cosine similarity of vectors with whole judgement & split judgement with dot (。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_judicial.pickle', 'rb') as f:\n",
    "    normal_judicial_json = pickle.load(f)\n",
    "\n",
    "accident_judicial.extend([ {\n",
    "    'JFULL': x['JFULLX']['JFULLCONTENT']} \n",
    "    for x in normal_judicial_json \n",
    "    if x.get('JFULLX') ])\n",
    "    #if x.get('JFULLX') and not ('車禍' in x['JFULLX']['JFULLCONTENT'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14904"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_judicial_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 經100筆判決書測試後發現，將有提到車禍的判決，與query判決進行比對，會因為判決很長，稀釋了語義，若用句號切斷，相似度會較為明顯，如下案例，\n",
    "#### 整體文本相似度為 0.1258，但部分段落，有相似度高達 0.6以上，所以未來應該會儲存每段向量、整體向量，並做一些EDA，確認好的評判方式。\n",
    "\n",
    "### 案例\n",
    "##### Split corpus similarity:  [tensor([[0.6438]]), '汽\\r\\n    車行駛時，駕駛人應注意車前狀況及兩車並行之間隔，並隨\\r\\n    時採取必要之安全措施；道路交通安全規則第94條第1項、\\r\\n    第3項前段分別定有明文']\n",
    "##### Split corpus similarity:  [tensor([[0.6339]]), '又被告過失\\r\\n    行為與系爭機車損害間具有相當因果關係，自應負侵權行為\\r\\n    損害賠償責任']\n",
    "##### Split corpus similarity:  [tensor([[0.6187]]), '又汽車在同一車道行\\r\\n    駛時，除擬超越前車外，後車與前車之間應保持隨時可以煞\\r\\n    停之距離，不得任意以迫近或其他方式，迫使前車讓道']\n",
    "##### 判決書有「車禍」字串\n",
    "##### Whole corpus similarity: \n",
    "##### tensor([[0.1258]])\n",
    "\n",
    "#### 2. 以前100筆判決書觀察，高相似度(cosine similarity)的結果，會提到 車 與 負面意涵(事故/痛苦等)，符合 車禍，車 + 禍害 的文字意涵，但也有不準的時候，\n",
    "#### 例如: Split corpus similarity:  [tensor([[0.6030]]), '\\r\\n三、原告所主張之事實，業據其提出與所述相符之系爭契約、系\\r\\n    爭車輛新領牌照登記書及行車執照、支票及退票理由單、存\\r\\n    證信函及回執、票據明細查詢表（見本院卷第7 頁至第9 頁\\r\\n    、第74頁至第77頁、第91頁至第97頁）']\n",
    "\n",
    "#### 所以下一步應該是如上所述，EDA後，進行100筆標記，評估各種方案的成效(CTR, NDCG等指標)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Split corpus similarity:  [tensor([[0.6178]]), '然\\r\\n    參酌原告自陳：系爭汽車係被告蔡秀美透過車行購買等語（\\r\\n    見本院卷第75頁）；又被告間就系爭汽車係成立有償的買賣\\r\\n    關係等情，亦如前述']\n",
      "Split corpus similarity:  [tensor([[0.6134]]), '並聲明：被告就系爭汽車之所有權移轉行為（原告就\\r\\n    被告間系爭汽車之買賣行為，未聲明撤銷）應予撤銷']\n",
      "Split corpus similarity:  [tensor([[0.6075]]), '\\r\\n  ㈣綜上所述，原告依據民法第244條第2項規定，請求撤銷被告\\r\\n    間就系爭汽車之所有權移轉行為，為無理由，應予駁回']\n",
      "判決書無「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.3542]])\n",
      "****************************************************************************************************\n",
      "Split corpus similarity:  [tensor([[0.6049]]), '三、基於轄\\r\\n    區來往查核之機動性及便利性，報請搭乘自有汽車執行查核\\r\\n    作業，所需之交通費用請准以汽油收據核銷']\n",
      "判決書無「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.1259]])\n",
      "****************************************************************************************************\n",
      "Split corpus similarity:  [tensor([[0.6438]]), '汽\\r\\n    車行駛時，駕駛人應注意車前狀況及兩車並行之間隔，並隨\\r\\n    時採取必要之安全措施；道路交通安全規則第94條第1項、\\r\\n    第3項前段分別定有明文']\n",
      "Split corpus similarity:  [tensor([[0.6339]]), '又被告過失\\r\\n    行為與系爭機車損害間具有相當因果關係，自應負侵權行為\\r\\n    損害賠償責任']\n",
      "Split corpus similarity:  [tensor([[0.6187]]), '又汽車在同一車道行\\r\\n    駛時，除擬超越前車外，後車與前車之間應保持隨時可以煞\\r\\n    停之距離，不得任意以迫近或其他方式，迫使前車讓道']\n",
      "判決書有「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.1258]])\n",
      "****************************************************************************************************\n",
      "Split corpus similarity:  [tensor([[0.6143]]), '次按汽車\\r\\n    行駛時，駕駛人應注意車前狀況及兩車並行之間隔，並隨時\\r\\n    採取必要之安全措施，不得在道路上蛇行，或以其他危險方\\r\\n    式駕車，道路交通安全規則第94條第3項亦有明文']\n",
      "判決書有「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.1297]])\n",
      "****************************************************************************************************\n",
      "Split corpus similarity:  [tensor([[0.6104]]), '惟原告所承保系爭車輛係106年2月出廠，有行車執照\\r\\n    附卷可稽（見本院卷第8頁），至前揭車禍發生時即107年3\\r\\n    月23日止已使用1年2月，揆諸前揭說明，以新品換舊品而更\\r\\n    換之零件，自應予以折舊']\n",
      "判決書有「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.1558]])\n",
      "****************************************************************************************************\n",
      "100\n",
      "Split corpus similarity:  [tensor([[0.6390]]), '臺南市車輛行車事故鑑定委員會之鑑定意見，容有\\r\\n    違誤']\n",
      "判決書有「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.1170]])\n",
      "****************************************************************************************************\n",
      "Split corpus similarity:  [tensor([[0.6030]]), '\\r\\n三、原告所主張之事實，業據其提出與所述相符之系爭契約、系\\r\\n    爭車輛新領牌照登記書及行車執照、支票及退票理由單、存\\r\\n    證信函及回執、票據明細查詢表（見本院卷第7 頁至第9 頁\\r\\n    、第74頁至第77頁、第91頁至第97頁）']\n",
      "判決書無「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.1645]])\n",
      "****************************************************************************************************\n",
      "Split corpus similarity:  [tensor([[0.6267]]), '\\r\\n    原告主張其係直行車輛而遭被告撞擊云云，尚難採信']\n",
      "判決書有「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.1678]])\n",
      "****************************************************************************************************\n",
      "Split corpus similarity:  [tensor([[0.6996]]), '又「停」標字，用以指示車輛至此必須停車再\\r\\n      開']\n",
      "Split corpus similarity:  [tensor([[0.6615]]), '另按汽車行駛時，\\r\\n      駕駛人應注意車前狀況，並隨時採取必要之安全措施；「\\r\\n      慢」字係用以警告車輛駕駛人前面路況變遷，應減速慢行\\r\\n      ']\n",
      "Split corpus similarity:  [tensor([[0.6450]]), '跟被告發生車禍的人是許耀煌，所\\r\\n    以許耀煌也有責任，原告的損失應該是被告與許耀煌共同負\\r\\n    擔等語']\n",
      "Split corpus similarity:  [tensor([[0.6222]]), '\\r\\n  (二)按汽車行駛至無號誌之交岔路口，支線道車應暫停讓幹線\\r\\n      道車先行']\n",
      "Split corpus similarity:  [tensor([[0.6093]]), '又系爭汽車係由許\\r\\n      耀煌向原告租借使用，此有營業有客車租日合約書1份可\\r\\n      參（見本院卷第25頁）']\n",
      "判決書有「車禍」字串\n",
      "Whole corpus similarity: \n",
      "tensor([[0.2294]])\n",
      "****************************************************************************************************\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "query_embedding = model.encode('車禍', convert_to_tensor=True)\n",
    "all_vecs = []\n",
    "\n",
    "for idx, case in enumerate(accident_judicial):\n",
    "    show_flag = False\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)\n",
    "\n",
    "    text_sim_sort = sorted([[util.cos_sim(query_embedding, model.encode(paragraph, convert_to_tensor=True)), paragraph]\n",
    "    for paragraph in case['JFULL'].split('。')], reverse=True)\n",
    "\n",
    "    for x in text_sim_sort:\n",
    "        if x[0] > 0.6:\n",
    "            print('Split corpus similarity: ', x)\n",
    "            show_flag = True\n",
    "    if show_flag:\n",
    "        if '車禍' in case['JFULL']:\n",
    "            print('判決書有「車禍」字串')\n",
    "        else:\n",
    "            print('判決書無「車禍」字串')\n",
    "        print('Whole corpus similarity: ')\n",
    "        print(util.cos_sim(query_embedding, model.encode(case['JFULL'], convert_to_tensor=True)))\n",
    "        print('*'*100)\n",
    "\n",
    "    all_vecs.extend(text_sim_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.301264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.085484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.015458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.250720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.299657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.344262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.699597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                vec\n",
       "count  23307.000000\n",
       "mean       0.301264\n",
       "std        0.085484\n",
       "min       -0.015458\n",
       "25%        0.250720\n",
       "50%        0.299657\n",
       "75%        0.344262\n",
       "max        0.699597"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vecs_df = pd.DataFrame([ float(x[0][0][0]) for x in all_vecs], columns=['vec'])\n",
    "all_vecs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vecs_df.to_excel('vecs_v2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相似度分佈，呈現常態分佈，含有車禍的判決書，超過0.4相似度的比例較高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](vec_bins_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 未實作部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test22](dev_spec2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e1437b994b2bf7ab90c1347218170795c830319bf39f9fdbb384fad56e42629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
